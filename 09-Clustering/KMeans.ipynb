{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from plot_silhouette import plot_silhouette_scores\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "# suppress future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(iris.data)\n",
    "features = iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_per_k = [KMeans(n_clusters=k).fit(X)\n",
    "                for k in range(1, 10)]\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(np.arange(len(inertias))+1,inertias,marker=\"o\")\n",
    "plt.xlabel('Number of Clusters, K')\n",
    "plt.ylabel('WCSS');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = [silhouette_score(X, model.labels_)\n",
    "                     for model in kmeans_per_k[1:]]\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(range(2, 10), silhouette_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "plot_df['truth'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "plt.scatter(plot_df['petal length (cm)'], plot_df['petal width (cm)'],c=kmeans_per_k[n_clusters-1].labels_,cmap='viridis')\n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('petal width (cm)')\n",
    "plt.title('KMeans Clustering');\n",
    "# fig = px.scatter(plot_df, x='petal length (cm)', y='petal width (cm)', color=kmeans_per_k[n_clusters-1].labels_,\n",
    "#                  hover_data=['truth'])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = silhouette_samples(X, kmeans_per_k[n_clusters-1].labels_)\n",
    "plt.scatter(plot_df['petal length (cm)'], plot_df['petal width (cm)'],c=si,cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('petal width (cm)')\n",
    "plt.title('Silhouette Scores');\n",
    "# fig = px.scatter(plot_df, x='petal length (cm)', y='petal width (cm)', color=si,\n",
    "#                  hover_data=['truth'])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df['clusters'] = kmeans_per_k[n_clusters-1].labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(plot_df.drop('truth', axis=1), hue='clusters', palette='Dark2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = kmeans_per_k[n_clusters-1].cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_df = pd.DataFrame(centers, columns=iris.feature_names)\n",
    "print(centers_df)\n",
    "sns.heatmap(centers_df, annot=True, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = 554\n",
    "class_names = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "X,y = fetch_openml(data_id=data_id, return_X_y=True, as_frame=False, parser='auto') # will return numpy arrays\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_per_k = [KMeans(n_clusters=k, n_init='auto').fit(X)\n",
    "                for k in range(1, 15)]\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,5))\n",
    "# plt.plot(np.arange(len(inertias))+1,inertias,marker=\"o\")\n",
    "# plt.xlabel('Number of Clusters, K')\n",
    "# plt.ylabel('WCSS');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WCSS Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes about 8 minutes to run\n",
    "\n",
    "# silhouette_scores = [silhouette_score(X, model.labels_)\n",
    "#                      for model in kmeans_per_k[1:]]\n",
    "\n",
    "# plt.figure(figsize=(8, 3))\n",
    "# plt.plot(np.arange(len(silhouette_scores))+2, silhouette_scores, \"bo-\")\n",
    "# plt.xlabel(\"$k$\")\n",
    "# plt.ylabel(\"Silhouette score\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_centers = 7\n",
    "km = KMeans(k_centers)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame(X)\n",
    "plot_df['clusters'] = km.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = UMAP(n_components=2)\n",
    "umap.fit(X)\n",
    "u = umap.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(u[:,0], u[:,1], c=km.labels_)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Center Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_centers = centers.reshape(k_centers,28,28)\n",
    "fig, ax = plt.subplots(1,k_centers, figsize=(10,4))\n",
    "for axi, center in zip(ax.flat, plot_centers):\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.imshow(center, interpolation='nearest',cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Features of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = km.cluster_centers_.argsort()[:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top = 50\n",
    "plot_main = np.zeros((k_centers,784))\n",
    "for i in range(k_centers):\n",
    "    plot_main[i, order_centroids[i,0:n_top]] = 1\n",
    "plot_main = plot_main.reshape(k_centers, 28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,k_centers, figsize=(10,4))\n",
    "for axi, center in zip(ax.flat, plot_main):\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.imshow(center, interpolation='nearest',cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", \"from\", \"subject\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose a subset of categories \n",
    "categories = [\n",
    " 'rec.autos',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'rec.sport.hockey',\n",
    " 'sci.space'\n",
    "]\n",
    "\n",
    "dataset = fetch_20newsgroups(\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "    subset=\"all\",\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(max_df=.5,min_df=100,stop_words=sw, token_pattern=r'(?u)\\b[a-zA-Z]+(?:-[a-zA-Z]+)*\\b')\n",
    "X = tf.fit_transform(dataset.data)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdf = pd.DataFrame(X.toarray(), columns=tf.get_feature_names_out())\n",
    "Xdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_per_k = [KMeans(n_clusters=k, n_init='auto', random_state=42).fit(X)\n",
    "                for k in range(1, 30)]\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.arange(len(inertias))+1,inertias,marker=\"o\")\n",
    "plt.xlabel('Number of Clusters, K')\n",
    "plt.ylabel('WCSS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = [silhouette_score(X, model.labels_)\n",
    "                     for model in kmeans_per_k[1:]]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.arange(len(silhouette_scores))+2, silhouette_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "kmeans = MiniBatchKMeans(k, n_init='auto')\n",
    "kmeans.fit(X)\n",
    "labs = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tf.get_feature_names_out()\n",
    "for i in range(k):\n",
    "    print(\"Cluster %d:\" %(i+1), end='')\n",
    "    for ind in order_centroids[i, :15]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## might need to install wordcloud\n",
    "## conda install -c conda-forge wordcloud\n",
    "## or\n",
    "## pip install wordcloud\n",
    "\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = kmeans.n_clusters\n",
    "\n",
    "# Loop through each cluster to create a word cloud\n",
    "for cluster in range(num_clusters):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    # Filter rows belonging to the current cluster\n",
    "    cluster_data = Xdf[kmeans.labels_ == cluster]\n",
    "    \n",
    "    # Compute mean TF-IDF scores for words in this cluster\n",
    "    word_freq = cluster_data.mean(axis=0)  # Mean TF-IDF per word\n",
    "    \n",
    "    # Convert to dictionary (only keep words with nonzero TF-IDF)\n",
    "    word_dict = word_freq[word_freq > 0].to_dict()\n",
    "    \n",
    "    # Generate the word cloud\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate_from_frequencies(word_dict)\n",
    "    \n",
    "    # Display the word cloud\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Cluster {cluster+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = UMAP(n_components=2).fit_transform(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Udf = pd.DataFrame(X_embedded, columns=['U1,','U2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(row, terms, n=10):\n",
    "    top_indices = np.argsort(row)[::-1][:n]  # Get indices of top N TF-IDF values\n",
    "    top_words = [terms[i] for i in top_indices if row[i] > 0]  # Only keep nonzero words\n",
    "    return \", \".join(top_words)\n",
    "\n",
    "\n",
    "# Apply function to get top words per document\n",
    "Udf[\"top_words\"] = Xdf.apply(lambda row: get_top_words(row.values, terms, n=5), axis=1)\n",
    "\n",
    "# Create UMAP scatter plot with hover text\n",
    "fig = px.scatter(\n",
    "    x=X_embedded[:, 0], \n",
    "    y=X_embedded[:, 1], \n",
    "    color=kmeans.labels_, \n",
    "    hover_data={\"Top Words\": Udf[\"top_words\"]},  # Show top words\n",
    "    labels={'color': 'Cluster'},\n",
    "    title='UMAP'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun application of k-means:  Image color segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_image\n",
    "china = load_sample_image(\"china.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(xticks=[], yticks=[])\n",
    "ax.imshow(china);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = china / 255\n",
    "data = data.reshape(427*640, 3)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique colors\n",
    "pd.DataFrame(data).drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![colors](colors.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 # choose how many colors\n",
    "kmeans = MiniBatchKMeans(k, n_init='auto')\n",
    "#kmeans = KMeans(n_clusters=k, n_init='auto')\n",
    "kmeans.fit(data)\n",
    "labs = kmeans.predict(data)\n",
    "new_colors = kmeans.cluster_centers_[labs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.arange(k)\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "#line1 = ax.scatter(x,y)\n",
    "for i in range(k):\n",
    "    ax.plot(x1[i], 0, marker='o', color=tuple(kmeans.cluster_centers_[i,:]),markersize=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_recolored = new_colors.reshape(china.shape)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16,6), subplot_kw=dict(xticks=[], yticks=[]))\n",
    "fig.subplots_adjust(wspace=0.05)\n",
    "ax[0].imshow(china)\n",
    "ax[0].set_title('Original Image', size=16)\n",
    "ax[1].imshow(china_recolored)\n",
    "ax[1].set_title(str(k)+'-color Image', size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shared",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
