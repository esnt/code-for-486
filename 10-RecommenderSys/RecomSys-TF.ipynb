{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Concatenate, Multiply, Dense, Dropout, Input\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for getting movie recommendations based on the highest predicted ratings\n",
    "def get_top_recommendations_tf(user, model, user_encoder, item_encoder, id_to_name, df, n_recommendations=10):\n",
    "    # Encode the user ID\n",
    "    encoded_user = user_encoder.transform([user])[0]\n",
    "    \n",
    "    # # Get all unique movie IDs and encode them\n",
    "    all_movies = df['movieid'].unique()\n",
    "    encoded_movies = item_encoder.transform(all_movies)\n",
    "    \n",
    "    # # Filter out movies the user has already rated\n",
    "    rated_movies = df[df['userid'] == user]['movieid'].unique()\n",
    "    encoded_rated_movies = item_encoder.transform(rated_movies)\n",
    "\n",
    "    #unrated_movies = np.setdiff1d(all_movies, rated_movies)\n",
    "    # encoded_unrated_movies = item_encoder.transform(unrated_movies)\n",
    "    encoded_unrated_movies = np.setdiff1d(encoded_movies, encoded_rated_movies)\n",
    "    unrated_movies = item_encoder.inverse_transform(encoded_unrated_movies)\n",
    "\n",
    "    # Prepare the user input for the model (repeat the user ID for each movie)\n",
    "    user_input = np.array([encoded_user] * len(encoded_unrated_movies))\n",
    "    \n",
    "    # Predict ratings for all unrated movies\n",
    "    predictions = model.predict([user_input, encoded_unrated_movies])\n",
    "    predictions = np.clip(predictions, 0,5)\n",
    "    \n",
    "    # Combine movie IDs with their predicted ratings\n",
    "    predicted_ratings = list(zip(unrated_movies, predictions.flatten()))\n",
    "    \n",
    "    # Sort the predicted ratings\n",
    "    predicted_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top N recommendations\n",
    "    top_recommendations = predicted_ratings[:n_recommendations]\n",
    "    \n",
    "    # Print the top N recommendations\n",
    "    print(f'Top {n_recommendations} recommendations for User {user}:')\n",
    "    print('-----')\n",
    "    for movie_id, rating in top_recommendations:\n",
    "        movie_name = id_to_name[movie_id]\n",
    "        print(f'{movie_name} ({round(rating, 3)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read in Data\n",
    "\n",
    "## movies\n",
    "movies = pd.read_csv('movies.csv',dtype={'movieid':str})\n",
    "id_to_name = movies.set_index('movieid')['title'].to_dict()\n",
    "## Class ratings\n",
    "class_ratings = pd.read_csv('class_ratings_f24.csv', dtype={'movieid': str})\n",
    "user_ids = class_ratings['userid'].unique()\n",
    "n_ratings = class_ratings.groupby('userid').size()\n",
    "users = zip(user_ids, n_ratings)\n",
    "## MovieLens ratings\n",
    "df = pd.read_csv('ratings_subset.csv', dtype={'userid': str, 'movieid': str, 'rating': float})\n",
    "## combine class ratings with ratings from MovieLens\n",
    "df = pd.concat([df, class_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare data for tensorflow model \n",
    "## Creates a unique numeric number for each user and each movie\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "df['user'] = user_encoder.fit_transform(df['userid'])\n",
    "df['item'] = item_encoder.fit_transform(df['movieid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create training and test data\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=7)\n",
    "X_train = [train_data['user'].values, train_data['item'].values]\n",
    "y_train = train_data['rating']\n",
    "\n",
    "X_test = [test_data['user'].values, test_data['item'].values]\n",
    "y_test = test_data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model input values\n",
    "num_users = df[\"userid\"].nunique()\n",
    "num_items = df[\"movieid\"].nunique()\n",
    "latent_dim = 10 #This is a hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Approaches to Recommender Systems\n",
    "There are certainly many deep learning approaches for building recommender systems, but two possible model choices are neural collaborative filter (NCF) and deep matrix factorization (DMF).\n",
    "\n",
    "### Neural Collaborative Filtering (NCF)\n",
    "NCF combines traditional collaborative filtering techniques with neural networks to enhance the recommendation system's capability to capture complex user-item interactions. It explicitly models the matrix factorization under the neural network framework.  Then it extends beyond matrix factorization by integrating a multi-layer perceptron (MLP) to learn the user-item interaction function.\n",
    "\n",
    "### Deep Matrix Factorization (DMF)\n",
    "DMF focuses on enhancing traditional matrix factorization methods by incorporating neural networks. It focuses on improving the embeddings' quality and the interactions between the embeddings (users and items). It tries to take these better representations (embeddings) of users and items in the shared latent space to make more accurate predictions of user-item interactions. At its core, DMF uses embedding layers for users and items, similar to traditional matrix factorization but benefits from the non-linear transformations provided by subsequent neural network layers.\n",
    "\n",
    "\n",
    "### Key Differences\n",
    "*  NCF generally introduces more complexity through its use of both linear (matrix factorization) and non-linear (MLP) components, whereas DMF focuses on deepening the matrix factorization approach with neural network layers.\n",
    "* NCF explicitly models both linear and non-linear interactions between users and items, offering a broader scope in capturing the nuances of user preferences. DMF primarily enhances the latent feature interactions through deep learning, improving upon traditional matrix factorization without fundamentally altering its linear nature.\n",
    "* NCF offers greater flexibility in modeling different types of interactions but at the cost of increased complexity. DMF maintains a focused enhancement of matrix factorization, potentially making it more accessible for those already familiar with matrix factorization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define inputs\n",
    "user_input = Input(shape=(1,), name='user_input')\n",
    "item_input = Input(shape=(1,), name='item_input')\n",
    "\n",
    "# Embeddings\n",
    "user_embedding = Embedding(input_dim=num_users, output_dim=latent_dim, name='user_embedding')(user_input)\n",
    "item_embedding = Embedding(input_dim=num_items, output_dim=latent_dim, name='item_embedding')(item_input)\n",
    "\n",
    "# Flatten embeddings\n",
    "user_vec = Flatten(name='flatten_user')(user_embedding)\n",
    "item_vec = Flatten(name='flatten_item')(item_embedding)\n",
    "\n",
    "# Element-wise multiply (Matrix Factorization Part)\n",
    "multiply_vec = Multiply(name='multiply')([user_vec, item_vec])\n",
    "\n",
    "# Concatenate the multiply vector with the flattened user and item vectors\n",
    "concat_vec = Concatenate(name='concatenate')([user_vec, item_vec, multiply_vec])\n",
    "\n",
    "# Dense layers (MLP Part)\n",
    "dense = Dense(128, activation='relu', name='dense1')(concat_vec)\n",
    "dense = Dropout(0.2, name='dropout1')(dense)\n",
    "dense = Dense(64, activation='relu', name='dense2')(dense)\n",
    "dense = Dropout(0.2, name='dropout2')(dense)\n",
    "output = Dense(1, activation=None, name='output')(dense)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[user_input, item_input], outputs=output)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Summary\n",
    "#model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "21163/21163 [==============================] - 24s 1ms/step - loss: 0.8037 - val_loss: 0.6858\n",
      "Epoch 2/5\n",
      "21163/21163 [==============================] - 26s 1ms/step - loss: 0.6632 - val_loss: 0.6616\n",
      "Epoch 3/5\n",
      "21163/21163 [==============================] - 24s 1ms/step - loss: 0.6269 - val_loss: 0.6463\n",
      "Epoch 4/5\n",
      "21163/21163 [==============================] - 24s 1ms/step - loss: 0.6010 - val_loss: 0.6406\n",
      "Epoch 5/5\n",
      "21163/21163 [==============================] - 24s 1ms/step - loss: 0.5781 - val_loss: 0.6415\n"
     ]
    }
   ],
   "source": [
    "## Train model\n",
    "n_epochs = 5\n",
    "history = model.fit(X_train, y_train, epochs=n_epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6614/6614 [==============================] - 2s 325us/step - loss: 0.6399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6398596167564392"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 429us/step\n",
      "Top 10 recommendations for User Caleb Christensen:\n",
      "-----\n",
      "Lord of the Rings: The Return of the King, The (2003) (4.547999858856201)\n",
      "Mulholland Drive (2001) (4.2870001792907715)\n",
      "Sin City (2005) (4.263999938964844)\n",
      "Kill Bill: Vol. 1 (2003) (4.203000068664551)\n",
      "Old Boy (2003) (4.172999858856201)\n",
      "Donnie Darko (2001) (4.125)\n",
      "Memento (2000) (4.110000133514404)\n",
      "Kill Bill: Vol. 2 (2004) (4.10099983215332)\n",
      "Spirited Away (Sen to Chihiro no kamikakushi) (2001) (4.09499979019165)\n",
      "City of God (Cidade de Deus) (2002) (4.061999797821045)\n",
      "\n",
      "\n",
      "16/16 [==============================] - 0s 411us/step\n",
      "Top 10 recommendations for User Emma Ouzts:\n",
      "-----\n",
      "The Martian (2015) (4.5289998054504395)\n",
      "Pride & Prejudice (2005) (4.519999980926514)\n",
      "Intouchables (2011) (4.513999938964844)\n",
      "Blind Side, The  (2009) (4.498000144958496)\n",
      "Spotlight (2015) (4.441999912261963)\n",
      "Harry Potter and the Prisoner of Azkaban (2004) (4.409999847412109)\n",
      "Finding Nemo (2003) (4.409999847412109)\n",
      "Pirates of the Caribbean: The Curse of the Black Pearl (2003) (4.406000137329102)\n",
      "Room (2015) (4.406000137329102)\n",
      "Monsters, Inc. (2001) (4.40500020980835)\n",
      "\n",
      "\n",
      "19/19 [==============================] - 0s 373us/step\n",
      "Top 10 recommendations for User James Christensen:\n",
      "-----\n",
      "Lord of the Rings: The Two Towers, The (2002) (4.318999767303467)\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001) (4.285999774932861)\n",
      "Lord of the Rings: The Return of the King, The (2003) (4.2729997634887695)\n",
      "Dark Knight, The (2008) (4.224999904632568)\n",
      "Whiplash (2014) (4.165999889373779)\n",
      "Inception (2010) (4.123000144958496)\n",
      "Intouchables (2011) (4.063000202178955)\n",
      "City of God (Cidade de Deus) (2002) (4.006999969482422)\n",
      "WALL·E (2008) (4.002999782562256)\n",
      "Avengers: Infinity War - Part I (2018) (3.997999906539917)\n",
      "\n",
      "\n",
      "17/17 [==============================] - 0s 404us/step\n",
      "Top 10 recommendations for User Jessa:\n",
      "-----\n",
      "Avengers, The (2012) (3.684999942779541)\n",
      "Avengers: Infinity War - Part I (2018) (3.611999988555908)\n",
      "Edge of Tomorrow (2014) (3.507999897003174)\n",
      "Pirates of the Caribbean: The Curse of the Black Pearl (2003) (3.493000030517578)\n",
      "Iron Man (2008) (3.492000102996826)\n",
      "X2: X-Men United (2003) (3.4649999141693115)\n",
      "Thor: Ragnarok (2017) (3.446000099182129)\n",
      "Pride & Prejudice (2005) (3.433000087738037)\n",
      "Harry Potter and the Goblet of Fire (2005) (3.430999994277954)\n",
      "King's Speech, The (2010) (3.430999994277954)\n",
      "\n",
      "\n",
      "18/18 [==============================] - 0s 378us/step\n",
      "Top 10 recommendations for User Madison:\n",
      "-----\n",
      "King's Speech, The (2010) (4.2829999923706055)\n",
      "Dark Knight, The (2008) (4.2829999923706055)\n",
      "Avengers: Infinity War - Part I (2018) (4.281000137329102)\n",
      "The Martian (2015) (4.2769999504089355)\n",
      "Whiplash (2014) (4.27400016784668)\n",
      "Thor: Ragnarok (2017) (4.252999782562256)\n",
      "Big Short, The (2015) (4.234000205993652)\n",
      "The Imitation Game (2014) (4.21999979019165)\n",
      "Guardians of the Galaxy 2 (2017) (4.218999862670898)\n",
      "Edge of Tomorrow (2014) (4.2179999351501465)\n",
      "\n",
      "\n",
      "18/18 [==============================] - 0s 397us/step\n",
      "Top 10 recommendations for User Rebz27:\n",
      "-----\n",
      "Intouchables (2011) (4.75600004196167)\n",
      "Inception (2010) (4.749000072479248)\n",
      "Whiplash (2014) (4.73799991607666)\n",
      "Pianist, The (2002) (4.710000038146973)\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001) (4.702000141143799)\n",
      "Interstellar (2014) (4.697999954223633)\n",
      "City of God (Cidade de Deus) (2002) (4.691999912261963)\n",
      "Memento (2000) (4.690000057220459)\n",
      "Departed, The (2006) (4.684999942779541)\n",
      "Big Short, The (2015) (4.683000087738037)\n",
      "\n",
      "\n",
      "18/18 [==============================] - 0s 385us/step\n",
      "Top 10 recommendations for User Ryan Corry:\n",
      "-----\n",
      "The Imitation Game (2014) (4.456999778747559)\n",
      "The Martian (2015) (4.453000068664551)\n",
      "Remember the Titans (2000) (4.449999809265137)\n",
      "Bourne Identity, The (2002) (4.434000015258789)\n",
      "Catch Me If You Can (2002) (4.420000076293945)\n",
      "Help, The (2011) (4.410999774932861)\n",
      "About Time (2013) (4.381999969482422)\n",
      "Beautiful Mind, A (2001) (4.38100004196167)\n",
      "Spotlight (2015) (4.366000175476074)\n",
      "Boondock Saints, The (2000) (4.354000091552734)\n",
      "\n",
      "\n",
      "18/18 [==============================] - 0s 384us/step\n",
      "Top 10 recommendations for User Savage:\n",
      "-----\n",
      "Spirited Away (Sen to Chihiro no kamikakushi) (2001) (4.817999839782715)\n",
      "City of God (Cidade de Deus) (2002) (4.729000091552734)\n",
      "Dr. Horrible's Sing-Along Blog (2008) (4.7170000076293945)\n",
      "Whiplash (2014) (4.715000152587891)\n",
      "Lives of Others, The (Das leben der Anderen) (2006) (4.697000026702881)\n",
      "Memento (2000) (4.697000026702881)\n",
      "Serenity (2005) (4.689000129699707)\n",
      "Room (2015) (4.683000087738037)\n",
      "Howl's Moving Castle (Hauru no ugoku shiro) (2004) (4.677999973297119)\n",
      "Kiss Kiss Bang Bang (2005) (4.676000118255615)\n",
      "\n",
      "\n",
      "19/19 [==============================] - 0s 355us/step\n",
      "Top 10 recommendations for User Spencer Wilson:\n",
      "-----\n",
      "Mulholland Drive (2001) (4.2789998054504395)\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001) (4.24399995803833)\n",
      "Old Boy (2003) (4.2179999351501465)\n",
      "Lord of the Rings: The Two Towers, The (2002) (4.183000087738037)\n",
      "There Will Be Blood (2007) (4.169000148773193)\n",
      "Lord of the Rings: The Return of the King, The (2003) (4.169000148773193)\n",
      "City of God (Cidade de Deus) (2002) (4.160999774932861)\n",
      "Donnie Darko (2001) (4.1539998054504395)\n",
      "Memento (2000) (4.130000114440918)\n",
      "Sin City (2005) (4.105999946594238)\n",
      "\n",
      "\n",
      "18/18 [==============================] - 0s 386us/step\n",
      "Top 10 recommendations for User TalmageA:\n",
      "-----\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001) (4.995999813079834)\n",
      "Lord of the Rings: The Two Towers, The (2002) (4.992000102996826)\n",
      "Spirited Away (Sen to Chihiro no kamikakushi) (2001) (4.638999938964844)\n",
      "Inside Out (2015) (4.514999866485596)\n",
      "Incredibles, The (2004) (4.501999855041504)\n",
      "Toy Story 3 (2010) (4.479000091552734)\n",
      "Howl's Moving Castle (Hauru no ugoku shiro) (2004) (4.46999979019165)\n",
      "Dark Knight, The (2008) (4.466000080108643)\n",
      "Monsters, Inc. (2001) (4.453000068664551)\n",
      "WALL·E (2008) (4.442999839782715)\n",
      "\n",
      "\n",
      "18/18 [==============================] - 0s 383us/step\n",
      "Top 10 recommendations for User Tyler Zaugg:\n",
      "-----\n",
      "King's Speech, The (2010) (4.564000129699707)\n",
      "The Martian (2015) (4.545000076293945)\n",
      "Room (2015) (4.5269999504089355)\n",
      "Whiplash (2014) (4.507999897003174)\n",
      "The Imitation Game (2014) (4.4679999351501465)\n",
      "Edge of Tomorrow (2014) (4.4679999351501465)\n",
      "Intouchables (2011) (4.464000225067139)\n",
      "Arrival (2016) (4.459000110626221)\n",
      "Thor: Ragnarok (2017) (4.455999851226807)\n",
      "Big Short, The (2015) (4.454999923706055)\n",
      "\n",
      "\n",
      "18/18 [==============================] - 0s 387us/step\n",
      "Top 10 recommendations for User Xela Marchant:\n",
      "-----\n",
      "Serenity (2005) (4.163000106811523)\n",
      "Inside Man (2006) (4.111999988555908)\n",
      "Avengers, The (2012) (4.093999862670898)\n",
      "Room (2015) (4.054999828338623)\n",
      "Pride & Prejudice (2005) (4.025000095367432)\n",
      "Edge of Tomorrow (2014) (4.025000095367432)\n",
      "The Martian (2015) (4.000999927520752)\n",
      "Intouchables (2011) (3.98799991607666)\n",
      "King's Speech, The (2010) (3.98799991607666)\n",
      "Inside Out (2015) (3.9830000400543213)\n",
      "\n",
      "\n",
      "18/18 [==============================] - 0s 401us/step\n",
      "Top 10 recommendations for User bradyheinig:\n",
      "-----\n",
      "Lord of the Rings: The Two Towers, The (2002) (4.369999885559082)\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001) (4.349999904632568)\n",
      "Avengers: Infinity War - Part I (2018) (4.0920000076293945)\n",
      "Hobbit: The Desolation of Smaug, The (2013) (4.079999923706055)\n",
      "Dark Knight, The (2008) (4.025000095367432)\n",
      "The Hobbit: The Battle of the Five Armies (2014) (4.0229997634887695)\n",
      "Harry Potter and the Half-Blood Prince (2009) (4.000999927520752)\n",
      "X-Men: The Last Stand (2006) (3.9809999465942383)\n",
      "Transformers (2007) (3.9760000705718994)\n",
      "X2: X-Men United (2003) (3.9739999771118164)\n",
      "\n",
      "\n",
      "18/18 [==============================] - 0s 416us/step\n",
      "Top 10 recommendations for User brandon-keele:\n",
      "-----\n",
      "Lord of the Rings: The Two Towers, The (2002) (4.958000183105469)\n",
      "Lord of the Rings: The Return of the King, The (2003) (4.8979997634887695)\n",
      "Toy Story 3 (2010) (4.7729997634887695)\n",
      "Shrek (2001) (4.771999835968018)\n",
      "Incredibles, The (2004) (4.76800012588501)\n",
      "Despicable Me (2010) (4.76200008392334)\n",
      "Spirited Away (Sen to Chihiro no kamikakushi) (2001) (4.757999897003174)\n",
      "Ratatouille (2007) (4.734000205993652)\n",
      "Monsters, Inc. (2001) (4.697999954223633)\n",
      "Harry Potter and the Half-Blood Prince (2009) (4.672999858856201)\n",
      "\n",
      "\n",
      "18/18 [==============================] - 0s 372us/step\n",
      "Top 10 recommendations for User brycemartin:\n",
      "-----\n",
      "Lord of the Rings: The Return of the King, The (2003) (4.991000175476074)\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001) (4.991000175476074)\n",
      "Lord of the Rings: The Two Towers, The (2002) (4.974999904632568)\n",
      "Dark Knight, The (2008) (4.874000072479248)\n",
      "Inception (2010) (4.874000072479248)\n",
      "Gladiator (2000) (4.824999809265137)\n",
      "Boondock Saints, The (2000) (4.738999843597412)\n",
      "Star Trek (2009) (4.73799991607666)\n",
      "Pirates of the Caribbean: The Curse of the Black Pearl (2003) (4.72599983215332)\n",
      "Batman Begins (2005) (4.7230000495910645)\n",
      "\n",
      "\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "Top 10 recommendations for User daphne:\n",
      "-----\n",
      "Inception (2010) (3.930000066757202)\n",
      "Lord of the Rings: The Return of the King, The (2003) (3.924999952316284)\n",
      "Inside Man (2006) (3.9200000762939453)\n",
      "Girl with the Dragon Tattoo, The (Män som hatar kvinnor) (2009) (3.8919999599456787)\n",
      "Departed, The (2006) (3.888000011444092)\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001) (3.888000011444092)\n",
      "Boondock Saints, The (2000) (3.88700008392334)\n",
      "Pirates of the Caribbean: The Curse of the Black Pearl (2003) (3.884000062942505)\n",
      "Memento (2000) (3.884000062942505)\n",
      "The Martian (2015) (3.88100004196167)\n",
      "\n",
      "\n",
      "16/16 [==============================] - 0s 461us/step\n",
      "Top 10 recommendations for User razedori:\n",
      "-----\n",
      "Spirited Away (Sen to Chihiro no kamikakushi) (2001) (4.635000228881836)\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001) (4.571000099182129)\n",
      "Lord of the Rings: The Two Towers, The (2002) (4.570000171661377)\n",
      "Lord of the Rings: The Return of the King, The (2003) (4.533999919891357)\n",
      "Whiplash (2014) (4.511000156402588)\n",
      "Dark Knight, The (2008) (4.478000164031982)\n",
      "City of God (Cidade de Deus) (2002) (4.474999904632568)\n",
      "Inside Out (2015) (4.459000110626221)\n",
      "Lives of Others, The (Das leben der Anderen) (2006) (4.439000129699707)\n",
      "Toy Story 3 (2010) (4.4029998779296875)\n",
      "\n",
      "\n",
      "18/18 [==============================] - 0s 367us/step\n",
      "Top 10 recommendations for User rebz27:\n",
      "-----\n",
      "Avengers, The (2012) (4.994999885559082)\n",
      "Intouchables (2011) (4.9730000495910645)\n",
      "Avengers: Infinity War - Part I (2018) (4.928999900817871)\n",
      "Guardians of the Galaxy 2 (2017) (4.89900016784668)\n",
      "Remember the Titans (2000) (4.8979997634887695)\n",
      "Iron Man (2008) (4.892000198364258)\n",
      "The Martian (2015) (4.890999794006348)\n",
      "Inside Out (2015) (4.890999794006348)\n",
      "Captain America: Civil War (2016) (4.870999813079834)\n",
      "Thor: Ragnarok (2017) (4.870999813079834)\n",
      "\n",
      "\n",
      "18/18 [==============================] - 0s 393us/step\n",
      "Top 10 recommendations for User shannon:\n",
      "-----\n",
      "Dark Knight, The (2008) (4.4679999351501465)\n",
      "Intouchables (2011) (4.408999919891357)\n",
      "Inception (2010) (4.386000156402588)\n",
      "Gladiator (2000) (4.296999931335449)\n",
      "Interstellar (2014) (4.291999816894531)\n",
      "Whiplash (2014) (4.269000053405762)\n",
      "Departed, The (2006) (4.257999897003174)\n",
      "Avengers: Infinity War - Part I (2018) (4.25600004196167)\n",
      "Prestige, The (2006) (4.248000144958496)\n",
      "Batman Begins (2005) (4.2170000076293945)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for user in user_ids:\n",
    "    get_top_recommendations_tf(user, model, user_encoder, item_encoder, id_to_name, df, 10)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### deep matrix factorization\n",
    "\n",
    "user_input = Input(shape=(1,))\n",
    "item_input = Input(shape=(1,))\n",
    "\n",
    "user_embedding = Embedding(num_users, latent_dim, name='user_embedding')(user_input)\n",
    "item_embedding = Embedding(num_items, latent_dim, name='item_embedding')(item_input)\n",
    "\n",
    "user_latent = Flatten()(user_embedding)\n",
    "item_latent = Flatten()(item_embedding)\n",
    "\n",
    "# Instead of separating GMF and MLP, DMF combines embeddings \n",
    "# and directly applies deep learning\n",
    "\n",
    "concat_latent = Concatenate()([user_latent, item_latent])\n",
    "\n",
    "dense = Dense(64, activation='relu')(concat_latent)\n",
    "dense = Dropout(0.5)(dense)\n",
    "dense = Dense(32, activation='relu')(dense)\n",
    "dense = Dropout(0.5)(dense)\n",
    "\n",
    "predictions = Dense(1)(dense)\n",
    "\n",
    "model_dmf = Model(inputs=[user_input, item_input], outputs=predictions)\n",
    "model_dmf.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "\n",
    "#model = deep_matrix_factorization_model(num_users, num_items, latent_dim)\n",
    "model_dmf.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model \n",
    "n_epochs = 5\n",
    "history_dmf = model_dmf.fit(X_train, y_train, epochs=n_epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "model_dmf.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get recommendations\n",
    "get_top_recommendations_tf('shannon', model_dmf, user_encoder, item_encoder, id_to_name, df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
